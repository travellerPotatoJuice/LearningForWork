# 硬件结构

## CPU是如何进行工作的





## 从磁盘到寄存器

离CPU越近，速度越快，价格越贵：

磁盘<内存<L3 Cache<L2 Cache<L1 Cache<寄存器



**寄存器：**

速度最快，一般要求在半个时钟周期内完成读写，也就是0.x纳秒的级别



**Cache：**

一般用SRAM（Static Random-Access Memory, 静态随机存储器）实现，掉电后数据会丢失。

L1 Cache：每个CPU核心都有，通常分成指令缓存和数据缓存，2~4个时钟周期内完成读写，大小几十KB~几百KB

L2 Cache：每个CPU核心都有，10~20个时钟周期内完成读写，大小在几百 KB 到几 MB

L3 Cache：多个CPU共用，20~60个时钟周期内完成读写，大小几MB~几十MB

![image-20240407210906509](image/image-20240407210906509.jpg)

**内存：**

一般用DRAM（Dynamic Random-Access Memory, 静态随机存储器）实现。数据会被存储在电容里，电容会不断漏电，所以需要「定时刷新」电容。速度大概在200~300时钟周期。



**硬盘：**

断电后数据不会丢失，固态硬盘叫SSD，机械硬盘叫HDD

内存比SSD快10~100倍，内存比HDD快10w倍

![image-20240407210630371](image/image-20240407210630371.jpg)



<font size=5>**Cache存取原理**</font>

![image-20240407214739059](image/image-20240407214718805.jpg)

提升数据缓存命中率：按照内存中的存储顺序读写元素

提升指令缓存命中率：不要在分支之内进行频繁跳跃

提升多核CPU的缓存命中率：将线程绑定在某个CPU核心上运行



## 缓存内存的数据一致性

<font size=5>**Cache和内存的一致性**</font>

**写直达（write through）**

+ 判断数据在不在缓存
  + 不在，直接写回内存
+ 在，先写回缓存，再写回内存

每次写都要写回内存，速度变慢了



**写回（write back）**

一种延迟写策略，写完缓存不立刻写回内存，只在不得不写回内存的时候才写

+ 判断数据在不在缓存
  + 在，直接写缓存
+ 不在，查看block里存放的别的内存地址的数据是不是脏的
  + 脏的，将数据写回内存
+ 不是脏的，从内存中读取自己要写的数据到cache
+ 写cache并且标记为脏的



<font size=5>**不同核心内Cache的一致性**</font>

两个原则。一个是CPU核心对共享的值进行修改之后，需要让别的CPU知道自己修改了（**写传播**）。第二个原则是不同 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的（**事务的串行化**）



**MESI协议**

**总线嗅探**：当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心。（需要CPU一直监听别的CPU的消息，CPU每次更新都要广播，无法实现事务串行化）